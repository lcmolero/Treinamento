{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formação Cientista de Dados - DSA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Big Data Real-Time Analytics com Python e Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projeto com Feedback 3 - Prevendo o Nível de Satisfação dos Clientes do Santander\n",
    "\n",
    "https://www.kaggle.com/c/santander-customer-satisfaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leonardo Molero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análise Exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação pacotes iniciais\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faz ajustes para não exibir warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Parametriza impressão dos gráficos dentro do notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carrega o dados de treino colocando a coluna ID como index\n",
    "df = pd.read_csv('dados/train.csv',index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checa o tamanho do dataframe\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualiza os dados treino\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica os tipos das colunas\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica os tipos de colunas agrupados (devido a quantidade de colunas)\n",
    "df.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifica estatísticas dos dados\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribuição da variável alvo\n",
    "df.groupby('TARGET').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota a distribuição da variável alvo\n",
    "sns.countplot(x='TARGET',data=df,palette=\"Paired_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procura por valores nulos\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria função para balancear os dados (undersampling) devido a diferença da distribuição da variável alvo\n",
    "\n",
    "# Importação dos pacotes\n",
    "import math\n",
    "\n",
    "# Criação da função de balanceamento\n",
    "def undersample(df, target_col, r=1):\n",
    "    falses = df[target_col].value_counts()[0]\n",
    "    trues = df[target_col].value_counts()[1]\n",
    "    relation = float(trues)/float(falses)\n",
    "    \n",
    "    if trues >= r*falses:\n",
    "        df_drop = df[df[target_col] == True]\n",
    "        drop_size = int(math.fabs(int((relation - r) * (falses))))\n",
    "    else: \n",
    "        df_drop = df[df[target_col] == False]\n",
    "        drop_size = int(math.fabs(int((r-relation) * (falses))))\n",
    "        \n",
    "    df_drop = df_drop.sample(drop_size)\n",
    "    df = df.drop(labels=df_drop.index, axis=0)\n",
    "    return df\n",
    "\n",
    "# Verifica os dados balanceados\n",
    "df = undersample(df, 'TARGET')\n",
    "df.groupby('TARGET').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plota a nova distribuição da variável alvo\n",
    "sns.countplot(x='TARGET',data=df,palette=\"Paired_r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza PCA para redução de dimensionalidade devido a grande quantidade de colunas\n",
    "\n",
    "# Importação do módulo\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Separa as varíavéis preditoras\n",
    "\n",
    "var = df.drop('TARGET', axis=1)\n",
    "y = df['TARGET']\n",
    "\n",
    "# Seleção de atributos\n",
    "pca = PCA(n_components = 5)\n",
    "fit = pca.fit(var)\n",
    "var_reduzido = pca.fit_transform(var)\n",
    "\n",
    "X = pd.DataFrame(var_reduzido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dados de treino e de teste\n",
    "\n",
    "#Importação dos módulos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separa 67% dos dados para treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina Modelo 01 Regressão Logística\n",
    "\n",
    "# Importação dos módulos\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Definindo os valores para o número de folds\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(num_folds, True)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo_1 = LogisticRegression()\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo_1, X, y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia Modelo 1: %.3f%%\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza os dados para tentar melhor o modelo\n",
    "\n",
    "# Importação do módulo\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "# Separando o array em componentes de input e output\n",
    "var = df.drop('TARGET',axis=1)\n",
    "y = df['TARGET']\n",
    "\n",
    "# Gerando os dados normalizados\n",
    "scaler = Normalizer().fit(var)\n",
    "normalizedVar = scaler.transform(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza PCA para redução de dimensionalidade nos dados normalizados\n",
    "\n",
    "# Importação do módulo\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Seleção de atributos\n",
    "pca = PCA(n_components = 5)\n",
    "fit = pca.fit(normalizedVar)\n",
    "var_reduzido = pca.fit_transform(normalizedVar)\n",
    "\n",
    "X = pd.DataFrame(var_reduzido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dados de treino e de teste\n",
    "\n",
    "#Importação dos módulos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separa 67% dos dados para treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina Modelo 02 Regressão Logística\n",
    "\n",
    "# Definindo os valores para o número de folds\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(num_folds, True)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo_2 = LogisticRegression()\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo_2, X, y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia Modelo 02: %.3f%%\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utiliza PCA para redução de dimensionalidade nos dados normalizados com mais componentes\n",
    "\n",
    "# Importação do módulo\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Seleção de atributos\n",
    "pca = PCA(n_components = 50)\n",
    "fit = pca.fit(normalizedVar)\n",
    "var_reduzido = pca.fit_transform(normalizedVar)\n",
    "\n",
    "X = pd.DataFrame(var_reduzido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separação dados de treino e de teste\n",
    "\n",
    "#Importação dos módulos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separa 67% dos dados para treino\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina Modelo 03 com Regressão Logística\n",
    "\n",
    "# Definindo os valores para o número de folds\n",
    "num_folds = 10\n",
    "seed = 7\n",
    "\n",
    "# Separando os dados em folds\n",
    "kfold = KFold(num_folds, True)\n",
    "\n",
    "# Criando o modelo\n",
    "modelo_3 = LogisticRegression()\n",
    "\n",
    "# Cross Validation\n",
    "resultado = cross_val_score(modelo_3, X, y, cv = kfold)\n",
    "\n",
    "# Print do resultado\n",
    "print(\"Acurácia Modelo 03: %.3f%%\" % (resultado.mean() * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treina Modelo 04 com XGBoost \n",
    "\n",
    "# Importação dos módulos\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Criando o modelo\n",
    "modelo_4 = XGBClassifier()\n",
    "\n",
    "# Treinando o modelo\n",
    "modelo_4.fit(X_train, y_train)\n",
    "\n",
    "# Fazendo previsões\n",
    "y_pred = modelo_4.predict(X_test)\n",
    "previsoes = [round(value) for value in y_pred]\n",
    "\n",
    "# Avaliando as previsões\n",
    "accuracy = accuracy_score(y_test, previsoes)\n",
    "print(\"Acurácia Modelo 04: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo 04 com XGBoost  apresentou acurácia melhor que os modelos de Regressão Logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importa dados de teste\n",
    "\n",
    "teste = pd.read_csv('dados/test.csv',index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(teste.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normaliza os dados de teste\n",
    "\n",
    "# Gerando os dados normalizados\n",
    "scaler = Normalizer().fit(teste)\n",
    "normalizedTeste = scaler.transform(teste)\n",
    "\n",
    "\n",
    "# Redução de dimensionalidade com PCA\n",
    "\n",
    "pca = PCA(n_components = 50)\n",
    "fit = pca.fit(normalizedTeste)\n",
    "teste_reduzido = pca.fit_transform(normalizedTeste)\n",
    "\n",
    "Z = pd.DataFrame(teste_reduzido)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "teste_pred = modelo_4.predict(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.DataFrame(teste.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission['TARGET'] = teste_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.groupby('TARGET').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.to_csv(sample_submission,'sample_submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
